---
title: "Anomaly Detection Methodology"
author: "Nathan Hoteling"
date: "4/23/2021"
output: html_document
---

<hr>
<br>
<br>

## Data

To illustrate the algorithm, we generate a simulated dataset consisting of ten variables measured over a period of 365 days.  Notice the pattern in the figure below.  Four simulated "anomalies" are injected into variable X04 at regular intervals.

```{r, include=FALSE}
#
# Make data
#
first_date <- ymd("2020-01-01")
n <- 365
dates=seq.Date(from = first_date, to = first_date+n-1, by="day")
vec <- c(1,1,3,3,5,9,11,9,5,3)
fake_anomalies <- data.frame(date=ymd(c("2020-02-01", "2020-05-01", "2020-08-01", "2020-11-01")),
                             mag = c(5, 5, 5, 5))

#
# Create some random data
#
set.seed(1234)  # set seed so it's repeatable
d <- lapply(seq_len(length(vec)), function(i) {
  nrm <- rnorm(n, vec[i], 2.5)
  nrm[ nrm < 0 ] <- 0
  #nrm <- nrm / max(nrm)
  return(nrm)
})
df.dat1 <- data.frame(do.call(cbind,d)) %>%
  mutate(date=dates, id = "Data 1") %>%
  left_join(fake_anomalies, by="date") %>%
  mutate(X4=ifelse(!is.na(mag),vec[4]+mag*vec[4],X4)) %>%#,
         #X3=ifelse(!is.na(mag),X3+mag*X3,X3),
         #X4=ifelse(!is.na(mag),X4+mag*X4,X4)) %>%
  dplyr::select(-mag)



#
# Plot some data
#
p.tile <- df.dat1 %>%
  pivot_longer(cols = 1:10) %>%
  mutate(name = paste("X",str_pad(parse_number(name),2,pad="0"),sep="")) %>%
  ggplot() +
  geom_tile(aes(x=date, y=name, fill=value)) +
  scale_fill_gradient(low="grey90", high="grey20") +
  labs(y="Variables", x="") +
  theme_minimal() +
  theme(legend.position="none") 
```

```{r, echo=FALSE, out.width="50%"}
p.tile
```




```{r, include=FALSE}

# Functions!
metric_euclidean <- function(df) {
  v_mean <- as.vector(t(colMeans(df)))
  d <- lapply(seq_len(nrow(df)), function(i) { 
    v1 <- as.vector(t(df[i,]))
    v2 <- v_mean
    dst <- as.numeric(dist(rbind(v1,v2), method="euclidean"))
    return(dst) 
  })
  return(unlist(d))
}

metric_mahalanobis <- function(df) {
  dst <- mahalanobis(df, colMeans(df), cov(df))
  return(dst)
}

metric_distance <- function(df, method="mahalanobis") {
  dst <- switch(method,
                  "euclidean" = metric_euclidean(df),
                  "mahalanobis" = metric_mahalanobis(df))
  return(dst) 
}
```

<br>

## Vector Distance

The basic principle behind the algorithm is that one can treat a collection of variables measured over time as a series of vectors.  These vectors can be compared with some nominal value representing "normal".  If nothing is defined _a priori_ then it is simple enough to use a statistical measure like mean or median.  

Each vector is compared to the nominal value with a vector distance metric.  In this case, Euclidean Distance and Mahalanobis Distance are used.  The former is a traditional method for distance measurements and the latter is somewhat more complex in that it uses covariance to account for dependencies between variables.

Once the vector distances are computed, the values are fit to some well-known distribution function, and a threshold value is derived from a user-defined probability value, similar to the selection of a p-value for significance measurements.  For example, the distributions below for Euclidean and Mahalanobis Distances are each fit to a Gamma Distribution function.  The threshold values are determined from the fits and represent the value for which there is a 1 in 1000 probability of randomly selecting a distance greater than this, given the fitted distribution.

```{r, echo=FALSE, message=FALSE, warning=FALSE}
# Get the vector distances
df1 <- df.dat1
dst1 <- metric_distance(df1[,-c(11,12)], method="euclidean")
dst2 <- metric_distance(df1[,-c(11,12)], method="mahalanobis")
df1$dst1 <- dst1
df1$dst2 <- dst2


# Fit the data
ft1 <- suppressWarnings(fitdist(df1$dst1, "gamma", method = "mle"))
ft2 <- suppressWarnings(fitdist(df1$dst2, "gamma", method = "mle"))


# Get threshold values from the fits
k <- 0.001
k1 <- qgamma(k, ft1$estimate["shape"], ft1$estimate["rate"], lower.tail=FALSE)
#k2 <- qchisq(k, df=9, lower.tail=FALSE)
k2 <- qgamma(k, ft2$estimate["shape"], ft2$estimate["rate"], lower.tail=FALSE)


# Make some plots
mx1 <- max(density(dst1)$y)
p.den1 <- ggplot(df.dat1) + 
  geom_histogram(aes(x=dst1, y=..density..), bins=50) +
  geom_function(fun=dgamma, args=list("shape"=ft1$estimate["shape"],
                                      "rate"=ft1$estimate["rate"]),
                color="red", size=0.6, alpha=0.8) +
  geom_segment(aes(x=k1, xend=k1,y=0,yend=0.5*mx1), color="red") +
  annotate("text", x=k1, y=0.5*mx1, label=paste("Threshold =",round(k1, digits=0)),
           hjust=-0.1, color="red") +
  labs(x="Distance", y="", title="Euclidean Distance | Gamma Distribution") +
  theme_minimal()

mx2 <- max(density(dst2)$y)
p.den2 <- ggplot(df.dat1) + 
  geom_histogram(aes(x=dst2, y=..density..), bins=50) +
  geom_function(fun=dgamma, args=list("shape"=ft2$estimate["shape"],
                                      "rate"=ft2$estimate["rate"]),
                color="red", size=0.6, alpha=0.8) +
  geom_segment(aes(x=k2, xend=k2,y=0,yend=0.5*mx2), color="red") +
  annotate("text", x=k2, y=0.5*mx2, label=paste("Threshold =",round(k2, digits=0)),
           hjust=-0.1, color="red") +
  labs(x="Distance", y="", title="Mahalanobis Distance | Gamma Distribution") +
  theme_minimal()
```


```{r, echo=FALSE, message=FALSE, warning=FALSE, out.width="50%"}
p.den1
p.den2
```

<br>

## Anomaly Metric

The anomaly metric is computed by normalizing the distances to the threshold value derived from the distribution fits.  In this way, anomalies can be quickly identified as any data point with a value greater than 1.0.  The figures below show the anomaly metric values determined from the simulated dataset.  The anomaly locations are depicted by grey bars and the algorithm results are highlighted by red dots.

```{r, include=FALSE}

# Calculate the anomaly metric
df1$m1 <- dst1 / k1
df1$m2 <- dst2 / k2


# Make some plots
p.m1 <- ggplot(df1) + 
  geom_segment(data=fake_anomalies, aes(x=date,xend=date,y=0,yend=Inf), size=3, color="grey80", alpha=0.5) +
  geom_col(aes(x=date, y=m1), width=1.0) + 
  geom_point(data=df1 %>% filter(m1>=1.0), mapping=aes(x=date, y=m1), size=2.5, color="red") +
  labs(x="", y="", title="Anomaly Metric | Euclidean") +
  theme_minimal()

p.m2 <- ggplot(df1) + 
  geom_segment(data=fake_anomalies, aes(x=date,xend=date,y=0,yend=Inf), size=3, color="grey80", alpha=0.5) +
  geom_col(aes(x=date, y=m2), width=1.0) + 
  geom_point(data=df1 %>% filter(m2>=1.0), mapping=aes(x=date, y=m2), size=2.5, color="red") +
  labs(x="",y="", title="Anomaly Metric | Mahalanobis") +
  theme_minimal()
```


```{r, , echo=FALSE, out.width="50%"}
p.m1
p.m2
```

<br>

## References

Nice description of Mahalanobis Distance and other stats things:  
https://blogs.sas.com/content/iml/2012/02/15/what-is-mahalanobis-distance.html  
https://blogs.sas.com/content/iml/2012/02/02/detecting-outliers-in-sas-part-3-multivariate-location-and-scatter.html  


Nice description of Gamma Distribution:  
https://towardsdatascience.com/gamma-distribution-intuition-derivation-and-examples-55f407423840  





